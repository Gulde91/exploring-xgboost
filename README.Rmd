---
title: "Readme"
output: github_document
---

```{r setup, include=FALSE}
library(knitr)

opts_chunk$set(echo = FALSE)
```

## Formål
Formålet med dette projekter er empirisk at undersøge og forstå visse grene af XGBoost algoritmen. 

### Data
Til at undersøge XGBoost bruges følgende datasæt:   
  - [Adult](https://rpubs.com/H_Zhu/235617)

### XGBoost og kategorisk data
```{r results_cat_features}
load("./results/cat_features_result.rda")
```

Her er blevet trænet 3 xgboost modeller med binær target på features der alle er kategoriske på adult-datasættet. Forskellen på modellerne er hvordan de kategoriske features er håndteret. Der er gjort på følgende måde:  
  1. De er blot taget med som numeriske features  
  2. De er one-hot encoded  
  3. Weight of evidens er benyttet  

Modellerne er blevet tunet med random search metoden, med en tune length på `r cat_features_result$tune_lenght`, på følgende parametre; `r cat_features_result$tune_params`.

Træningstiderne for de 3 modeller kan ses her:  
  1. Model med numeriske features: `r cat_features_result$time_num_model[[1]]` sekunder  
  2. Model med one hot encoded features: `r cat_features_result$time_one_hot_model[[1]]` sekunder  
  3. Model med weight of evidence encoded features: `r cat_features_result$time_woe_model[[1]]` sekunder  

En roc kurve med tilhørende auc værdier for hver af de 3 modeller ses i plottet.  
![](./results/cat_exp_roc_plot.jpg)

Til sidst er accuracy udregnet med et cutoff på 0.5 for hver model.   
  1. Model med numeriske features: `r round(cat_features_result$acc_num_model, 4)`   
  2. Model med one-hot encoded features: `r round(cat_features_result$acc_one_hot_model, 4)`  
  3. Model med weight of evidens encoded features: `r round(cat_features_result$acc_woe_model, 4)`  


### Sparse vs dense træningsdata
```{r results_sparse_dense}
load("./results/sparse_vs_dense_result.rda")
```

Her er blevet trænet 2 modeller på identisk datagrundlag (hvor kategoriske features er one-hot-encoded). Forskellen ligger i dataformatet til XGB-modellen. I det ene tilfælde er input til modellen en sparse matrix (dgCMatrix) og i det andet tilfælde er input en dense matrix (matrix). Den primære interesse er at finde ud af, hvor stor tidsforskellen er på at træne en XGB-model på henholdsvis sparse og dense data. Modellerne tunes med `r sparse_vs_dense_result$cv` fold crossvalidation over det samme random search grid med længden `r sparse_vs_dense_result$tune_lenght` på parametrene; `r sparse_vs_dense_result$tune_params`. Træningstiden kan ses her:  
  - Model på sparse data: `r sparse_vs_dense_result$time_sparse_model[[1]]` sekunder  
  - Model på dense data: `r sparse_vs_dense_result$time_dense_model[[1]]` sekunder  
Som der kan ses er modellen tunet på sparse data omtrent `r round(sparse_vs_dense_result$time_dense_model[[1]] / sparse_vs_dense_result$time_sparse_model[[1]], 1)` gange hurtigere end modellen tunet på dense data. 

### Missing data 
Xgboost kan som standard godt håndtere NA i data. Gain ved et split bliver udregnet ud fra data som ikke er NA og de resterende samples med NA bliver derefter assignet til den optimale direction. Der er dog den hage ved det, at hvis input er en sparse matrice, så bliver 0'er i data behandlet som NA. Her undersøges betydningen af at have NA i data og i hvilket format data er i (sparse eller dense matrix). Her imputeres NA i data og det gøres først random og bagefter systematisk. Kategoriske features er one-hot-encoded. 
  
##### Random imputation af NA
```{r results sparse dense with random NA}
load("./results/sparse_vs_dense_random_na_result.rda")

percent <- sparse_vs_dense_random_na_result$missing_list * 100
len <- length(percent)
```
Her er `r paste0(percent[1:(len-2)], "%")`, `r percent[len-1]`% og `r percent[len]`% af data imputeret med NA. Her er trænet 2 modeller på samme data og med samme random search grid (der kan naturligvis være forskel på hvilke parametre der er optimale) for hvert niveau af NA procent-delen. Det ene datasæt er encoded som en sparse matrix og det andet som en dense matrix. 

En roc kurve med tilhørende auc værdier for hver af de 2 modeller ses i plottet.  
```{r na random plots, out.width="50%"}
knitr::include_graphics(c(
  "./results/sparse_vs_dense_random_na_roc_plot_10_percent.jpg",
  "./results/sparse_vs_dense_random_na_roc_plot_20_percent.jpg"))

knitr::include_graphics(
  c("./results/sparse_vs_dense_random_na_roc_plot_30_percent.jpg",
    "./results/sparse_vs_dense_random_na_roc_plot_40_percent.jpg"))
```


Til sidst er accuracy udregnet med et cutoff på 0.5 for hver model.

```{r accuracy, results="asis"}
acc_measure <- sparse_vs_dense_random_na_result[grepl("^acc_", names(sparse_vs_dense_random_na_result))]

acc_measure <- unlist(acc_measure)

out <- list()

for (i in 1:length(acc_measure)) {
  data_type <- ifelse(grepl("dense", names(acc_measure[i])), "dense", "sparse")
  NA_percent <- substr(names(acc_measure[i]), 
                       regexpr("[0-9]{2}", names(acc_measure[i]))[1],
                       regexpr("[0-9]{2}", names(acc_measure[i]))[1]+1
                       )
  
  cat("  ", i, ".", " Model med ", data_type, 
      " encoding og ", NA_percent, "% NA ",
      round(acc_measure[i], 4),
      "\n", sep = "")
}
```
  
##### Systematisk imputation af NA
Her er xx % af data imputeret med NA. Her er trænet 2 modeller på samme data og med samme search grid (der kan naturligvis være forskel på hvilke parametre der er optimale). Det ene datasæt er encoded som en sparse matrix og det andet som en dense matrix. 

En roc kurve med tilhørende auc værdier for hver af de 2 modeller ses i plottet.  
![](./results/cat_exp_roc_plot.jpg) <!-- indsæt rigtigt plot -->

Til sidst er accuracy udregnet med et cutoff på 0.5 for hver model.   
  1. Model med sparse data: `r round(cat_features_result$acc_num_model, 4)`   
  2. Model med dense data: `r round(cat_features_result$acc_one_hot_model, 4)`  
